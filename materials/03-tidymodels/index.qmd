---
title: "Teaching modern modeling with tidymodels"
subtitle: "rstudio::conf(2022) <br> Designing the data science classroom"
author: "Maria Tackett"
footer: "[🔗 rstd.io/teach-ds-conf22](https://rstd.io/teach-ds-conf22) / Module 3"
logo: "../images/logo.png"
format: 
  revealjs:
    theme: ../slides.scss
    multiplex: true
    transition: fade
    slide-number: true
    incremental: false 
    chalkboard: true
execute:
  freeze: auto
  echo: true
---

# In progress

::: callout-warning
These slides are currently being designed and built.
:::

## Session outline

-   Add agenda

```{r}
#| message: false
#| warning: false

# load packages for slides
library(tidyverse)
library(openintro)
library(countdown)
```

# Teaching modern modeling

## GAISE guidelines

-   Teach statistical thinking.
    -   Teach statistics as an investigative process of problem-solving and decision-making.
    -   Give students experience with multivariable thinking.
-   Integrate real data with a context and purpose.
-   Use technology to explore concepts and analyze data.

See [Guidelines for Assessment and Instruction in Statistics Education (GAISE) 2016 Report](https://www.amstat.org/docs/default-source/amstat-documents/gaisecollege_full.pdf) for full report.

## Teaching modern regression

Facilitate opportunities for students to...

::: incremental
-   Regularly engage with **real-world applications and complex data**

-   Develop proficiency **using professional statistical software** and using a reproducible workflow

-   Identify **appropriate methods based on the primary analysis objective** - inference or prediction

-   Develop important non-technical skills, specifically written communication and teamwork
:::

# Introducing tidymodels

## Tidymodels

::: columns
::: {.column width="40%"}
![](images/hello-tidymodels.png){fig-align="center"}
:::

::: {.column width="60%"}
The **tidymodels** framework is a collection of packages for modeling and machine learning using tidyverse principles.

<br>

```{r}
#| eval: false

install.packages("tidymodels")
```
:::
:::

## Tidymodels

```{r}
#| message: true
#| warning: true

library(tidymodels)
```

## Data: Loans from Lending Club

The data is the [`loans_full_schema`](http://openintrostat.github.io/openintro/reference/loans_full_schema.html) data set from the **openintro** package and featured in the OpenIntro textbooks .
It contains information about 50,000 loans made through the Lending Club platform.
The variables we'll use in this analysis are

-   `interest_rate`: Interest rate of the loan the applicant received.
-   `debt_to_income`: Debt-to-income ratio.
-   `term`: The number of months of the loan the applicant received.
-   `delinq_2y`: Number of delinquencies on lines of credit in the last 2 years.

## Data: Loans from Lending Club

```{r}
library(openintro)
glimpse(loans_full_schema)
```

## Regression syntax

Fit a linear regression model to predict the interest rate using the debt to income ratio.

::: panel-tabset
## Base R

```{r}
base_lm <- lm(interest_rate ~ debt_to_income, data = loans_full_schema)
summary(base_lm)
```

## Tidymodels

```{r}
tidy_lm <- linear_reg() |> 
  set_engine("lm") |>
  fit(interest_rate ~ debt_to_income, data = loans_full_schema)

tidy(tidy_lm)
```
:::

## Model summaries using broom

Can utilize functions from the [**broom**](broom.tidymodels.org) package to produce tidy summaries of models fit using Base R or the tidymodels framework

-   `tidy()`: summarizes information about model components

-   `glance()`: reports information about the entire model

-   `augment()`: adds information about observations to a data set

## `tidy()`

::: panel-tabset
## `Base R`

```{r}
base_lm <- lm(interest_rate ~ debt_to_income, data = loans_full_schema)
tidy(base_lm)
```

## `Tidymodels`

```{r}
tidy_lm <- linear_reg() |> 
  set_engine("lm") |>
  fit(interest_rate ~ debt_to_income, data = loans_full_schema)
tidy(tidy_lm)
```
:::

## `glance()`

::: panel-tabset
## Base R

```{r}
glance(base_lm)
```

## Tidymodels

```{r}
glance(tidy_lm)
```
:::

## `augment()`

::: panel-tabset
## Base R

```{r}
#| code-line-numbers: "1"

base_lm_aug <- augment(base_lm)
base_lm_aug
```

## Tidymodels

```{r }
#| code-line-numbers: "1"

tidy_lm_aug <- augment(tidy_lm$fit)
tidy_lm_aug
```
:::

## Why Tidymodels?

There are advantages for more advanced modeling:

-   Consistent syntax for different model types (linear, logistic, random forest, Bayesian, etc.
-   Streamline modeling workflow
    -   Split data into train and test sets
    -   Transform and create new variables
    -   Assess model performance
    -   Use model for prediction and inference

# Teaching with tidymodels

## Tidymodels syntax

```{r}
linear_reg() |> 
  set_engine("lm") |>
  fit(interest_rate ~ debt_to_income, data = loans_full_schema) |>
  tidy()
```

Let's break down the syntax.

## 1️⃣ Specify model

```{r}
linear_reg() 
```

## 2️⃣ Set computational engine

```{r}
linear_reg() |> 
  set_engine("lm")
```

## 3️⃣ Fit the model

```{r}
linear_reg() |> 
  set_engine("lm") |>
  fit(interest_rate ~ debt_to_income, data = loans_full_schema)
```

## 4️⃣ Summarize output

```{r}
linear_reg() |> 
  set_engine("lm") |>
  fit(interest_rate ~ debt_to_income, data = loans_full_schema) |>
  tidy()
```

## Consistent syntax for other models

The syntax is the same if we fit a more advanced model, such as a logistic regression model.

. . .

*Fit a model to predict the loan term length (36 or 60 months) based on the loan amount.*

```{r}
logistic_reg() |>
  set_engine("glm") |>
  fit(factor(term) ~ loan_amount, data = loans_full_schema) |>
  tidy()
```

## Feature engineering

::: incremental
-   **Feature engineering** is the process of transforming raw variables in preparation for use in a statistical model.

-   You may be familiar doing feature engineering using dplyr before fitting the model.

-   The [recipes](https://recipes.tidymodels.org/) package makes it possible to do feature engineering as part of the modeling workflow using "dplyr-like" functions.
:::

## Example: Predicting interest rate

::: incremental
-   **Goal**: Fit a model to predict the interest rate based on the term, debt to income ratio, and number of delinquencies in the past two years.

-   We need to do the following to prepare the predictors for the model:

    -   Make `term` a factor.

    -   Mean-center `debt_to_income`.

    -   Split `delinq_2y` into the categories 0, 1, 2, 3+.
:::

## Feature engineering using dplyr

```{r}
# Feature engineering
loans_full_schema <- loans_full_schema |>
  mutate(term_fct = as_factor(term)) |>
  mutate(debt_to_income_cent = 
           debt_to_income - mean(debt_to_income, na.rm = TRUE)) |>
  mutate(delinq_2y_cat = 
           cut(delinq_2y, breaks = c(-Inf,0,1, 2, 3, Inf)))

# Fit the model 
lm(interest_rate ~ term_fct + debt_to_income_cent + delinq_2y_cat,
   data = loans_full_schema) |>
  tidy()
```

## Feature engineering with recipes

![Illustration by [Allison Horst](https://www.allisonhorst.com/)](images/recipes.png){fig-align="center"}

## Specify the variables

```{r}
interest_rec <- recipe(
  interest_rate ~ term + debt_to_income + delinq_2y, 
  data = loans_full_schema 
  )

interest_rec
```

## Define pre-processing steps

**Make `term` a factor.**

```{r}
interest_rec <- interest_rec |>
  step_mutate(term = as_factor(term))

interest_rec
```

## Define pre-processing steps

**Mean-center `debt_to_income`**.

```{r}
interest_rec <- interest_rec |>
  step_center(debt_to_income)

interest_rec
```

## Define pre-processing steps

**Break `delinq_2y` into the categories 0, 1, 2, 3+.**

```{r}
interest_rec <- interest_rec |>
  step_cut(delinq_2y, breaks = c(-Inf,0,1, 2, 3, Inf))

interest_rec
```

## Putting it all together

```{r}
interest_rec <- recipe(interest_rate ~ term + debt_to_income + delinq_2y,
                       data = loans_full_schema) |>
  step_mutate(term = as_factor(term))|>
  step_center(debt_to_income) |>
  step_cut(delinq_2y, breaks = c(-Inf,0,1, 2, 3, Inf))
```

## Putting it all together

```{r}
interest_rec
```

## Prep and bake to see created variables

```{r}
interest_rec |>
  prep()|>
  bake(loans_full_schema) |>
  head()
```

## Your turn!

## Fit the model using `workflow()`

**Workflows** bring together models and recipes, making them easier to apply to multiple data sets, e.g, training and test data.

. . .

**Specify the model**

```{r}
interest_spec <- linear_reg() |>
  set_engine("lm")
```

. . .

**Build workflow**

```{r}
interest_workflow <- workflow() |>
  add_model(interest_spec) |>
  add_recipe(interest_rec)
```

## View workflow

```{r}
interest_workflow
```

## Fit model to data

```{r}
interest_fit <- interest_workflow %>%
  fit(data = loans_full_schema)

tidy(interest_fit)
```

# Prediction + Model evaluation

## Make predictions

```{r}
interest_pred <- predict(interest_fit, loans_full_schema) |> 
  bind_cols(loans_full_schema |> select(interest_rate))

interest_pred
```

## Model evaluation: $R^2$

$R^2$ is the percent of variability in the interest rate explained by the model.

```{r}
rsq(interest_pred, truth = interest_rate, estimate = .pred)
```

## Model evaluation: $RMSE$

$RMSE$ is a measure of the error in the model predictions.

$$
RMSE = \sqrt{\frac{\sum_{i=1}^{n}(\hat{y}_i - y_i)^2}{n}}
$$

. . .

```{r}
rmse(interest_pred, truth = interest_rate, estimate = .pred)
```

## Your turn! (7 minutes)

# What is a limitation to the model evaluation we've done thus far?

## Splitting the data

Splitting the data into training and testing sets allows us to evaluate the model on new data.

. . .

**Split the data.**

```{r}
set.seed(0725) #to get same split each run
loans_split <- initial_split(loans_full_schema, prop = 0.8) #80% training
```

**Save the training data.**

```{r}
loans_train <- training(loans_split)
dim(loans_train)
```

**Save test data.**

```{r}
loans_test <- testing(loans_split)
dim(loans_test)
```

## Fit the model to the training data

We can fit the model specified in `interest_workflow` (model spec + recipe) to the training data.

```{r}
interest_train_fit <- interest_workflow |>
  fit(data = loans_train)

tidy(interest_train_fit)
```

## Evaluate performance on training data

**Calculate predictions**

```{r}
interest_train_pred <- predict(interest_train_fit, loans_train) |> 
  bind_cols(loans_train |> select(interest_rate))
```

**Evaluate model**

```{r}
rsq(interest_train_pred, truth = interest_rate, estimate = .pred)
```

```{r}
rmse(interest_train_pred, truth = interest_rate, estimate = .pred)
```

## Evaluate performance on testing data

**Calculate predictions**

```{r}
interest_test_pred <- predict(interest_train_fit, loans_test) |> 
  bind_cols(loans_test |> select(interest_rate))
```

**Evaluate model**

```{r}
rsq(interest_test_pred, truth = interest_rate, estimate = .pred)
```

```{r}
rmse(interest_test_pred, truth = interest_rate, estimate = .pred)
```

## Your turn!

## Discussion

::: question
-   What is something from this module you can implement in your data science course?

-   What is one potential challenge of implementing this content in your course?
:::

```{r}
countdown(minutes = 7, font_size = "1.5em")
```
